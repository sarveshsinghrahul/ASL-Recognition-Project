{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c640ed58",
   "metadata": {},
   "source": [
    "## Code to check GPU integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107df115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for g in gpus:\n",
    "            tf.config.experimental.set_memory_growth(g, True)\n",
    "        print(\"Enabled memory growth for GPUs:\", gpus)\n",
    "    except Exception as e:\n",
    "        print(\"Could not set memory growth:\", e)\n",
    "else:\n",
    "    print(\"No GPUs found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4dcc04",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks, regularizers\n",
    "import datetime\n",
    "\n",
    "# --- NEW IMPORTS FOR TRANSFER LEARNING ---\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6993f1f",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7698039",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = str(\"asl_alphabet_train\")\n",
    "IMG_SIZE = (200, 200)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "VAL_SPLIT = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc58e4",
   "metadata": {},
   "source": [
    "## Dataset imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aee890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset (subset=\"training\") and validation dataset (subset=\"validation\")\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d0131",
   "metadata": {},
   "source": [
    "## Class checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(\"Found classes:\", len(class_names))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "p = pathlib.Path(DATA_DIR)\n",
    "counts = {d.name: len(list(d.glob(\"*\"))) for d in p.iterdir() if d.is_dir()}\n",
    "for c, n in sorted(counts.items()):\n",
    "    print(f\"{c:20s} {n}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a655cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(train_ds)\n",
    "\n",
    "first_batch = next(iterator)\n",
    "\n",
    "images_batch, labels_batch = first_batch\n",
    "\n",
    "\n",
    "print(f\"Type of images_batch: {type(images_batch)}\")\n",
    "print(f\"Images batch shape: {images_batch.shape}\")\n",
    "print(f\"Labels batch shape: {labels_batch.shape}\")\n",
    "\n",
    "print(\"\\n--- Example from the batch ---\")\n",
    "print(f\"Shape of one image: {images_batch[0].shape}\")\n",
    "print(f\"Label for first image: {labels_batch[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8873c63b",
   "metadata": {},
   "source": [
    "## Optimize pipeline (for Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# We can use the same augmentation as before\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.1),  \n",
    "    tf.keras.layers.RandomZoom(0.1),    \n",
    "    tf.keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2), \n",
    "    tf.keras.layers.RandomBrightness(0.1), \n",
    "    tf.keras.layers.RandomContrast(0.1)    \n",
    "])\n",
    "\n",
    "# --- Apply augmentation, THEN MobileNet's specific pre-processing ---\n",
    "# This function scales pixels from [0, 255] to [-1, 1]\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# --- Apply pre-processing to validation data ---\n",
    "val_ds = val_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312022c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "input_shape = (*IMG_SIZE, 3) \n",
    "\n",
    "# 1. Load the \"Street Smart\" Base Model (MobileNetV2)\n",
    "# We don't include its final \"top\" layer\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=input_shape,\n",
    "    include_top=False, \n",
    "    weights='imagenet' # Load the knowledge from millions of images\n",
    ")\n",
    "\n",
    "# 2. FREEZE the expert's knowledge. \n",
    "# We don't want to re-train the part that knows about edges and textures.\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Build your new model on top\n",
    "model = models.Sequential([\n",
    "    # Start with the frozen expert\n",
    "    base_model,\n",
    "    \n",
    "    # Add our own classifier head\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.3), # A dropout of 0.3 is a good starting point\n",
    "    layers.Dense(num_classes, activation='softmax') # Your 29-class output\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy', # <-- Perfect for integer labels!\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log directory for this specific run\n",
    "# The datetime string makes each run unique in TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Create the TensorBoard callback\n",
    "tensorboard_callback = callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1  # This logs weight histograms every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04994072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback to stop training if validation accuracy doesn't improve\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3, # Stop after 3 epochs of no improvement\n",
    "    restore_best_weights=True # Automatically restore the best model weights\n",
    ")\n",
    "\n",
    "# Create a callback to save your best model to a file\n",
    "model_checkpoint = callbacks.ModelCheckpoint(\n",
    "    'model1.keras', # File name\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20 # Start with 20, EarlyStopping will stop it if it's done sooner\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopping,\n",
    "     model_checkpoint,\n",
    "     tensorboard_callback\n",
    "     ] # Pass in our helpers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb704a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "âœ… Clean Backup (asl_gpu_backup)",
   "language": "python",
   "name": "asl_gpu_backup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}