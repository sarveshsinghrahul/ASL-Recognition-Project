{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74df9b97",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b98bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1eaccb",
   "metadata": {},
   "source": [
    "### --- 1. INITIALIZE MEDIAPIPE ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762874670.824048  978160 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1762874670.873263  978268 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.0.7-0ubuntu0.24.04.2), renderer: llvmpipe (LLVM 20.1.2, 256 bits)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=True, # We are processing static images\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93257ece",
   "metadata": {},
   "source": [
    "### --- 2. DEFINE CLASSES AND DATA FOLDER ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb1c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'asl_alphabet_train'\n",
    "class_names = [\n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n",
    "    'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', \n",
    "    'del', 'nothing', 'space'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa1b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening asl_landmarks_v2.csv to write...\n",
      "Processing 3000 images for class: A\n",
      "Processing 3000 images for class: B\n",
      "Processing 3000 images for class: C\n",
      "Processing 3000 images for class: D\n",
      "Processing 3000 images for class: E\n",
      "Processing 3000 images for class: F\n",
      "Processing 3000 images for class: G\n",
      "Processing 3000 images for class: H\n",
      "Processing 3000 images for class: I\n",
      "Processing 3000 images for class: J\n",
      "Processing 3000 images for class: K\n",
      "Processing 3000 images for class: L\n",
      "Processing 3000 images for class: M\n",
      "Processing 3000 images for class: N\n",
      "Processing 3000 images for class: O\n",
      "Processing 3000 images for class: P\n",
      "Processing 3000 images for class: Q\n",
      "Processing 3000 images for class: R\n",
      "Processing 3000 images for class: S\n",
      "Processing 3000 images for class: T\n",
      "Processing 3000 images for class: U\n",
      "Processing 3000 images for class: V\n",
      "Processing 3000 images for class: W\n",
      "Processing 3000 images for class: X\n",
      "Processing 3000 images for class: Y\n",
      "Processing 3000 images for class: Z\n",
      "Processing 3000 images for class: del\n",
      "Processing 3000 images for class: nothing\n",
      "Processing 3000 images for class: space\n",
      "--- Dataset Creation Complete! ---\n",
      "New dataset saved as: asl_landmarks_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 3. CREATE THE NEW CSV FILE ---\n",
    "csv_file_name = 'asl_landmarks_v2.csv' # New name\n",
    "print(f\"Opening {csv_file_name} to write...\")\n",
    "\n",
    "# A 1D vector of 63 zeros. This is our \"nothing\" feature.\n",
    "ZERO_VECTOR = [0.0] * 63 \n",
    "\n",
    "with open(csv_file_name, mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    # --- 4. WRITE THE HEADER ROW ---\n",
    "    header = ['label']\n",
    "    for i in range(21): # 21 landmarks\n",
    "        header.extend([f'x{i}', f'y{i}', f'z{i}'])\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # --- 5. LOOP THROUGH ALL IMAGES ---\n",
    "    for label in class_names:\n",
    "        folder_path = os.path.join(DATA_DIR, label, '*.jpg')\n",
    "        image_files = glob.glob(folder_path)\n",
    "        print(f\"Processing {len(image_files)} images for class: {label}\")\n",
    "        \n",
    "        for image_path in image_files:\n",
    "            \n",
    "            # --- !!! NEW LOGIC !!! ---\n",
    "            # If the class is \"nothing\", don't even run MediaPipe.\n",
    "            # Just write the zero vector.\n",
    "            if label == 'nothing':\n",
    "                csv_writer.writerow([label] + ZERO_VECTOR)\n",
    "                continue # Go to the next image\n",
    "            # --- END NEW LOGIC ---\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "                \n",
    "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(rgb_image)\n",
    "\n",
    "            # --- 6. EXTRACT & NORMALIZE LANDMARKS ---\n",
    "            if results.multi_hand_landmarks:\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                \n",
    "                wrist = hand_landmarks.landmark[0]\n",
    "                landmark_vector = []\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    landmark_vector.append(landmark.x - wrist.x)\n",
    "                    landmark_vector.append(landmark.y - wrist.y)\n",
    "                    landmark_vector.append(landmark.z - wrist.z)\n",
    "                    \n",
    "                csv_writer.writerow([label] + landmark_vector)\n",
    "            \n",
    "            else:\n",
    "                # --- !!! NEW LOGIC FOR FISTS !!! ---\n",
    "                # If MediaPipe *fails* to find a hand for \"del\" or \"space\"\n",
    "                # (which are fists), we will ALSO treat this as a zero vector.\n",
    "                if label in ['del', 'space']:\n",
    "                    csv_writer.writerow([label] + ZERO_VECTOR)\n",
    "                # For all other classes ('A', 'B', etc.), if MediaPipe\n",
    "                # fails, we skip it as \"bad data\".\n",
    "                pass\n",
    "\n",
    "print(f\"--- Dataset Creation Complete! ---\")\n",
    "print(f\"New dataset saved as: {csv_file_name}\")\n",
    "hands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b00f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "âœ… MediaPipe Sender (env_mediapipe)",
   "language": "python",
   "name": "env_mediapipe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
